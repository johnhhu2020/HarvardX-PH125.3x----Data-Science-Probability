---
title: 'HarvardX PH125.3x -- Data Science: Probability'
author: "John HHU"
date: '2022-05-30'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.








## Course  /  Section 1: Discrete Probability  /  Section 1 Overview


# Section 1 Overview


Section 1 introduces you to Discrete Probability. Section 1 is divided into three parts:

[][*        Introduction to Discrete Probability*]
            *A discrete probability distribution counts occurrences that have countable or finite outcomes.*
[][*        Combinations and Permutations*]
            *When the order doesn't matter, it is a Combination. When the order does matter it is a Permutation*]
[][*        Addition Rule and Monty Hall*]
            *https://www.varsitytutors.com/hotmath/hotmath_help/topics/addition-rule-of-probability*
            *https://www.mathgoodies.com/lessons/vol6/addition_rules*
            *Google Monty Hall problem*

After completing Section 1, you will be able to:

        apply basic probability theory to categorical data.
        perform a Monte Carlo simulation to approximate the results of repeating an experiment over and over, including simulating the outcomes in the Monty Hall problem.
        distinguish between: sampling with and without replacement, events that are and are not independent, and combinations and permutations.
        apply the multiplication and addition rules, as appropriate, to calculate the probably of multiple events occurring.
        use sapply() instead of a for loop to perform element-wise operations on a function.

There are 3 assignments that use the DataCamp platform for you to practice your coding skills. There are also some quick probability calculations for you to perform directly on the edX platform as well, and there is a longer set of problems at the end of section 1.

This section corresponds to the following section of the course textbook.
https://rafalab.github.io/dsbook/probability.html#discrete-probability

We encourage you to use R to interactively test out your answers and further your learning.







## Course  /  Section 1: Discrete Probability  /  1.1 Introduction to Discrete Probability


# Discrete Probability


We start by covering some basic principles related to categorical data.  This subset of probability is referred to as [][*discrete probability*].  ***It will help us understand the probability theory we will later introduce for numeric and continuous data, which is more common in data science applications***.  Discrete probability is more useful in card games and we use these as examples.  The word probability is used in everyday language.  For example, Google's auto complete of, what are the chances of, gives us getting pregnant, having twins, and rain tomorrow.  Answering questions about probability is often hard, if not impossible.  Here, we discuss a mathematical definition of probability that does permit us to give precise answers to certain questions.  

For example, if I have two red beads and three blue beads inside an urn and I pick one at random, what is the probability of picking a red one?  Our intuition tells us that the answer is 2/5, or 40%.  A precise definition can be given by noting that ***there are five possible outcomes of which two satisfy the condition necessary for the event "pick a red bead."***  Because each of the five outcomes has the same chance of occurring, we conclude that the probability is 0.4 for red and 0.6 for blue.  

[][*A more tangible way to think about the probability of an event is as a proportion of times the event occurs when we repeat the experiment over and over independently and under the same conditions*].  Before we continue, let's introduce some notation.  We use the notation probability of A to denote the probability of an event A happening.  We use the very general term event to refer to things that can happen when something happens by chance.  

For example, in our previous example, the event was picking a red bead.  In a political poll, in which we call 100 likely voters
at random, an example of an event is calling 48 Democrats and 52 Republicans.  [][***In data science applications, we will often deal with continuous variables*].  In these cases, events will often be things like, ***is this person taller than 6 feet?***  In this case, we write events in a more mathematical form.  For example, x greater than 6.  We'll see more of these examples later.  Here, we focus on categorical data and discrete probability.


[][Textbook link]

This video corresponds to the textbook section on discrete probability External link.
https://rafalab.github.io/dsbook/probability.html#discrete-probability


[][Key points]

    The probability of an event is the proportion of times the event occurs when we repeat the experiment independently under the same conditions.
    Pr(A) = probability of event A
    An event is defined as an outcome that can occur when when something happens by chance.
    We can determine probabilities related to discrete variables (picking a red bead, choosing 48 Democrats and 52 Republicans from 100 likely voters) and continuous variables (height over 6 feet).



![](C:/Users/JJ/Pictures/discrete probability.png)

![](C:/Users/JJ/Pictures/googles auto complete of what are the chance of ....png)

![](C:/Users/JJ/Pictures/having rains tomorrow.png)

![](C:/Users/JJ/Pictures/picking beads rnadomly from a urn.png)

![](C:/Users/JJ/Pictures/a precise definition giving that there are 5 possible outcomes of which 2 satisfy the condition necessary.png)

![](C:/Users/JJ/Pictures/A more tangible way to think about the probability of an event is as a condition of times the events occurs.png)

![](C:/Users/JJ/Pictures/paobability of a notation.png)

![](C:/Users/JJ/Pictures/term event to refering things can happen when something happens by chance.png)

![in data science we will often deal with continuous variables.png](C:/Users/JJ/Pictures/in data science we will often deal with continuous variables.png)

![](C:/Users/JJ/Pictures/events sample in data science dealing with continuous variable.png)

![](C:/Users/JJ/Pictures/then we write it in a more mathematical form.png)









# Monte Carlo Simulations


Computers provide a way to actually perform the simple random experiments, such as the one we did before.  Pick a bead at random from a bag or an urn with 3 blue beads and 2 red ones.  [][*Random number generators*] permit us to mimic the process of picking at random.  An example in R is the sample() function.  We demonstrate its use showing you some code.  First, use the rep() function to generate the urn.  We create an urn with 2 red and 3 blues.  You can see when we type beads we see this.  Now, we can use a sample() function to pick one at random.  If we type sample beads comma 1, in this case, we get a blue.  This line of code produces one random outcome.  Now, we want to repeat this experiment over and over.  

However, it is, of course, impossible to repeat forever.  Instead, we repeat the experiment a large enough number of times to make the results practically equivalent to doing it over and over forever.  [][*This is an example of a Monte Carlo simulation*].  Note that much of what mathematical and theoretical statisticians study--something we do not cover in this course--relates to providing rigorous definitions of *practically equivalent*, as well as studying how close a large number of experiment gets us to what happens in the limit, the limit meaning if we did it forever.  [][********Later in this module, we provide a practical approach to deciding what is large enough********].  

To perform our first Monte Carlo simulation, we use the replicate() function.  This permits us to repeat the same task any number of times we want.  Here, we repeat the random event 10,000 times.  We set B to be 10,000, then we use the replicate() function to sample from the beads 10,000 times.  We can now see if, in fact, our definition is in agreement with this Monte Carlo simulation approximation.  *We can use table(), for example, to see the distribution.  And then we can use prop.table() to give us the proportions*.  And we see that, in fact, the Monte Carlo simulation gives a very good approximation with 0.5962 for blue and 0.4038 for red.  We didn't get exactly 0.6 and exactly 0.4, but statistical theory tells us that, if we make B large enough, we can get as close as we want to those numbers.  We just covered a simple and not very useful example of Monte Carlo simulations.  

But we will use Monte Carlo simulation to estimate probabilities in cases in which it is harder to compute the exact ones.  Before we go into more complex examples, we still use simple ones to demonstrate the computing tools available in R.  Let's start by noting that we don't actually have to use replicate() in this particular example.  This is because the function sample() has an argument that permits us to pick more than one element from the urn.  However, by default, this selection occurs without replacement.  After a bead is selected, it is not put back in the urn.  Note what happens when we ask to randomly select 5 beads.  Let's do it over and over again.  Let's do it three times.  This results in a rearrangement that always has three blue and two red beads.  If we asked for six beads, then we get an error.  It tells us you don't have enough beads in here to get six.  

This is because it's doing it without replacement.  However, this function, the sample function, can be used directly--again, without the replicate--to repeat the same experiment of picking 1 out of 5 beads over and over under the same conditions.  To do this, we sample with replacement.  After we pick the bead we put it back in the urn.  We can tell sample to do this by changing the *replace = * argument which defaults to false to true.  We do it like this.  And when we do this, we see that we get very similar answers to what  we got using the replicate function.  


[][Textbook link]

This video corresponds to the textbook section on Monte Carlo simulations.
https://rafalab.github.io/dsbook/probability.html#monte-carlo-simulations


[][Key points]

    Monte Carlo simulations model the probability of different outcomes by repeating a random process a large enough number of times that the results are similar to what would be observed if the process were repeated forever.

    The sample() function draws random outcomes from a set of options.
    The replicate() function repeats lines of code a set number of times. It is used with sample() and similar functions to run Monte Carlo simulations.

Video code

Note that your exact outcome values from the Monte Carlo simulation will differ because the sampling is random.

beads <- rep(c("red", "blue"), times = c(2,3))    # create an urn with 2 red, 3 blue
beads    # view beads object
sample(beads, 1)    # sample 1 bead at random

B <- 10000    # number of times to draw 1 bead
events <- replicate(B, sample(beads, 1))    # draw 1 bead, B times
tab <- table(events)    # make a table of outcome counts
tab    # view count table
prop.table(tab)    # view table of outcome proportions



```{r}
beads = rep(c("red", "blue"), times = c(2, 3) )


sample(beads, 100, replace = T)


tab = table(sample(beads, 10000, replace = T))
prop.table(tab)
```



![](C:/Users/JJ/Pictures/computer provides us the random number enerators.png)

![](C:/Users/JJ/Pictures/sample function in r helps us apply a random experiment.png)

![](C:/Users/JJ/Pictures/use rep function to create a urn includes 2 red and 3 blue.png)


![](C:/Users/JJ/Pictures/and now we can produce 1 random outcome.png)

![](C:/Users/JJ/Pictures/monte carlo simulation.png)

![](C:/Users/JJ/Pictures/replicate function premits us to repeat same task any number of time we want.png)

![](C:/Users/JJ/Pictures/now we repeat the random event 10 thousand times and check the outcome.png)

![](C:/Users/JJ/Pictures/we can use table function to see the distribution.png)

![](C:/Users/JJ/Pictures/and use the prop.table function to see the proportions.png)

![](C:/Users/JJ/Pictures/default sample function repeat offers us without replacement experiment.png)

![](C:/Users/JJ/Pictures/sample one by one and we get this, without replacement.png)

![](C:/Users/JJ/Pictures/and now we don't have enough beads in urn.png)

![](C:/Users/JJ/Pictures/now check what happens on your own what happends if we change default replace arg from FALSE to T.png)









# Setting the Random Seed


The set.seed() function

Before we continue, we will briefly explain the following important line of code:

set.seed(1986) 

Throughout this book, we use random number generators. This implies that many of the results presented can actually change by chance, which then suggests that a frozen version of the book may show a different result than what you obtain when you try to code as shown in the book. This is actually fine since the results are random and change from time to time. However, if you want to to ensure that results are exactly the same every time you run them, you can set R’s random number generation seed to a specific number. Above we set it to 1986. We want to avoid using the same seed every time. A popular way to pick the seed is the year - month - day. For example, we picked 1986 on December 20, 2018:  2018 − 12 − 20 = 1986.

You can learn more about setting the seed by looking at the documentation:

?set.seed

In the exercises, we may ask you to set the seed to assure that the results you obtain are exactly what we expect them to be.
Important note on seeds in R 3.5 versus R 3.6 and later

When R updated to version 3.6 in early 2019, the default method for setting the seed changed. This means that exercises, videos, textbook excerpts and other code you encounter online may yield a different result based on your version of R.

[][*If you are running R 3.6 or later, you can revert to the original seed setting behavior by adding the argument sample.kind="Rounding". For example:*]

set.seed(1)
set.seed(1, sample.kind="Rounding")    # will make R 3.6 generate a seed as in R 3.5

Using the sample.kind="Rounding" argument will generate a message:

**non-uniform 'Rounding' sampler used**

This is not a warning or a cause for alarm - it is a confirmation that R is using the alternate seed generation method, and you should expect to receive this message in your console.

If you use R 3.6 or later, you should always use the second form of set.seed() in this course series (outside of DataCamp assignments). Failure to do so may result in an otherwise correct answer being rejected by the grader. In most cases where a seed is required, you will be reminded of this fact.


```{r}
set.seed(1986, sample.kind="Rounding")
```







# Using the mean Function for Probability


An important application of the mean() function

[][*In R, applying the mean() function to a logical vector returns the proportion of elements that are TRUE*]. It is very common to use the mean() function in this way to calculate probabilities and we will do so throughout the course.

Suppose you have the vector beads from a previous video:

beads <- rep(c("red", "blue"), times = c(2,3))
beads
[1] "red" "red" "blue" "blue" "blue"

To find the probability of drawing a blue bead at random, you can run:

mean(beads == "blue")
[1] 0.6

This code is broken down into steps inside R. First, R evaluates the logical statement beads == "blue", which generates the vector:

FALSE FALSE TRUE TRUE TRUE

When the mean function is applied, R coerces the logical values to numeric values, changing TRUE to 1 and FALSE to 0:

0 0 1 1 1

The mean of the zeros and ones thus gives the proportion of TRUE values. As we have learned and will continue to see, probabilities are directly related to the proportion of events that satisfy a requirement.






# Probability Distributions


[][***Defining a distribution for categorical outcomes is relatively straight forward***].  We simply assign a probability to each category.  In cases that can be thought of as beads in an urn, for each bead type, the proportion defines the distribution.  Another example comes from polling.  If you're are randomly calling likely voters from a population that has 44% Democrat, 44% Republican, 10% undecided, and 2% green, these proportions define the probability for each group.  For this example, the probability distribution is simply these four proportions.  

Again, categorical data makes it easy to define probability distributions.  However, later in applications that are more common in data science,  we will learn about probability distributions for continuous variables.  In this case, it'll get a little bit more complex.  But for now, we're going to stick to discrete probabilities before we move on.  


[][Textbook link]

This video corresponds to the textbook section on probability distributions.
https://rafalab.github.io/dsbook/probability.html#discrete-probability-distributions



[][Key points]

    The probability distribution for a variable describes the probability of observing each possible outcome.
    For discrete categorical variables, the probability distribution is defined by the proportions for each group.



![for each bead type, the proportion defines the distribution](C:/Users/JJ/Pictures/beads in a urn for each bead type.png)

![categorical data makes it easy to define probability distribution](C:/Users/JJ/Pictures/this proportion defines the probability for each group.png)

(  *A discrete probability distribution counts occurrences that have countable or finite outcomes. This is in contrast to a continuous distribution, where outcomes can fall anywhere on a continuum. Common examples of discrete distribution include the binomial, Poisson, and Bernoulli distributions.*  )









# Independence


We say that two events are independent if the outcome of one does not affect the other.  This classic example are coin tosses.  Every time we toss a fair coin, the probability of seeing heads is one half, regardless of what previous tosses have revealed.  The same is true when we pick beads from an urn, with replacement.  In the example we saw earlier, the probability of red was 0.40, regardless of previous draws.  Many examples of events that are not independent come from card games.  When we deal the first card, the probability of getting, say a King, is 1 in 13.  This is because there are 13 possibilities.  You can get an ace, a two, a three, a four, et cetera, 10, Jack, Queen, or King.  Now, if we deal a King for the first card, and I don't replace it, then the probability of getting a King in the second card is less, because there are only three Kings left.  The probability is 3 out of not 52, because we already dealt one card, but out of 51.  These events are, therefore, not independent.  

[][*The first outcome affects the second*].  To see an extreme case of non-independent events, consider an example of drawing five beads at random, without replacement, from an urn.  Three are blue, two are red.  I'm going to generate data like this using the sample() function and assign it to x.  You can't see the outcomes.  Now, if I ask you to guess the color of the first bead, what do you guess?  Since there's more blue beads, there's actually a 0.6 chance of seeing blue.  That's probably what you guess.  **But now I'm going to show you the outcomes of the other four**.  The second, third, fourth, and fifth outcomes you can see here.  You can see that the three blue beads have already come out.  This affects the probability of the first.  They are not independent.  So would you still guess blue?  Of course not.  Now you know that the probability of red is 1.  

These events are not independent.  The probabilities change once you see the other outcomes.  When events are not independent, conditional probabilities are useful and necessary to make correct calculations.  We already saw an example of a conditional probability.  We computed the probability that a second dealt card is a King, given that the first was a King.
In probability, we use the following notation.
We use this dash like this as a shorthand
for given that or conditional on, these are synonyms.
Note that, when two events, say A and B, are independent,
we have the following equation.
The probability of A given B is equal to the probability of A.
It doesn't matter what B is.
The probability A is unchanged.
This is the mathematical way of saying it.
And in fact, this can be considered the mathematical definition
of independence.
All right now, if we want to know the probability of two events, say A and B,
occurring, we can use the multiplication rule.
So the probability of A and B is equal to the probability of A multiplied
by the probability of B, given that A already happened.
Let's use blackjack as an example.
In blackjack, you get assigned to random cards, without replacement.
Then you can ask for more.
The goal is to get closer to 21 than the dealer, without going over.
Face cards are worth 10 points, so is the 10
card, that's worth 10 points too.
And aces are worth either 11 or 1.
So if you get an ace and a face card, you win automatically.
So, in blackjack, to calculate the chances of getting 21
in the following way, first we get an ace.
And then we get a face card or a 10.
We compute the probability of the first being an ace.
And then multiply by the probability of a face card or a 10,
given that the first card was an ace.
The calculation is 1 over 13 chance of getting an ace, times chance
of getting a card with value 10, given that we already
saw an ace, which is 16 out of 51.
We've already taken one card out.
This is approximately 2%.
The multiplicative rule also applies to more than two events.
We can use induction to expand for more than two.
So the probability of A and B and C is equal to the probability of A times
our probability of B, given that A happen, times the probability of C,
that A and B happen.
When we have independent events, the multiplication rule becomes simpler.
We simply multiply of three probabilities.
But we have to be very careful when we use
the multiplicative rule in practice.
We're assuming independence.
And this can result in very different and incorrect probability calculations
when we don't actually have independence.
This can have dire consequences.
For example, in a trial, if an expert doesn't really know the multiplication
rule and how to use it.
So let's use an example.
This is loosely based on something that actually happened.
Imagine a court case in which the suspect was described
to have a mustache and a beard.
And the prosecution brings in an expert to argue that because 1 in 10 men
have beards, and 1 in 5 men has mustaches, using the multiplication
rule, this means that only 2% of men have both beards
and mustaches, 1/10 times 1/5.
2% is a pretty unlikely event.
However, to multiply like this, we need to assume independence.
And in this case, it's clearly not true.
The conditional probability of a man having a mustache, conditional on them
having a beard, is quite high.
It's about 95%.
So the correct calculation actually gives us a much higher probability.
It's 9%, so there's definitely reasonable doubt.




![](C:/Users/JJ/Pictures/definition of independent.png)

![](C:/Users/JJ/Pictures/toss coin is a example of independent.png)

![with replacement](C:/Users/JJ/Pictures/pick bead from urn is also a independent.png)

![The first outcome affects the second](C:/Users/JJ/Pictures/not independent event example are card games.png)

![not independent events are without replacement card games.png](C:/Users/JJ/Pictures/not independent events are without replacement card games.png)

![compute the probability that the second dealt card is king, given that the first was king](C:/Users/JJ/Pictures/when events are not independent, conditional probabilities are useful and necessary.png)

![](C:/Users/JJ/Pictures/in probability we use following notation to represent conditional probability.png)

![](C:/Users/JJ/Pictures/notice when 2 events are independent, we have following equation.png)

![](C:/Users/JJ/Pictures/applies the multiplication rule to calculate the probability of 2 events occurring.png)

![so the probability of a and b is equal to the probability of a multiplied by the probability of b given that a already happened.png](C:/Users/JJ/Pictures/so the probability of a and b is equal to the probability of a multiplied by the probability of b given that a already happened.png)

![](C:/Users/JJ/Pictures/blackjack game winning rate is you first get ace card then get 10 or face card.png)

![](C:/Users/JJ/Pictures/the multiplicative rule also applies to more then two events.png)

![](C:/Users/JJ/Pictures/for independent events, the multiplication rule becomes simpler.png)

![](C:/Users/JJ/Pictures/how to know if the events are independent or not.png)

![](C:/Users/JJ/Pictures/having mustache and beard.png)

![](C:/Users/JJ/Pictures/1 in 10 men has beard and 1 in 5 men has mustache.png)

![assume independence, not true at all.png](C:/Users/JJ/Pictures/assume independence, not true at all.png)

![](C:/Users/JJ/Pictures/The conditional probability of a man having a mustache, conditional on them.png)













































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































